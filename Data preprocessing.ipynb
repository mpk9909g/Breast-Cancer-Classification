{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eb49954",
   "metadata": {},
   "source": [
    "## Project 3\n",
    " ### Team:3\n",
    "    \n",
    "    Matt Keeley\n",
    "    Jenny Yang\n",
    "    Shay Masood\n",
    "    Shreyansh Saraiya\n",
    "    Fatma Butun\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c185707",
   "metadata": {},
   "source": [
    "# OVERVIEW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9267f39b",
   "metadata": {},
   "source": [
    "### Here we aim to predict whether a breast tumor is benign or malignant based on certain cell features by using Machine Learning algorithm.\n",
    "### The result will be published on heroku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9837d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4df723",
   "metadata": {},
   "source": [
    "# Read csv and do data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b043b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_df = pd. read_csv(\"breast_cancer_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5442fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# breast_cancer_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3327d240",
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ed7eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the null columns where all values are null\n",
    "breast_cancer_df = breast_cancer_df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "breast_cancer_df = breast_cancer_df.dropna()\n",
    "breast_cancer_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0536e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the output as target\n",
    "target = breast_cancer_df[\"diagnosis\"]\n",
    "# target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc1f00d",
   "metadata": {},
   "source": [
    "## Group 1: Select every single input column as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1125e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input, begin with all inputs\n",
    "\n",
    "features = breast_cancer_df[['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270bea63",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make synthetic data\n",
    "\n",
    "# # Fit a kernel density model using GridSearchCV to determine the best parameter for bandwidth\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.neighbors import KernelDensity\n",
    "# bandwidth_params = {'bandwidth': np.arange(0.01,1,0.05)}\n",
    "# grid_search = GridSearchCV(KernelDensity(), bandwidth_params)\n",
    "# grid_search.fit(features)\n",
    "# kde = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4ce8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate 100 new sample from this dataset\n",
    "# synthetic_data = kde.sample(100, random_state=42)\n",
    "\n",
    "# synthetic_data = pd.DataFrame(synthetic_data, columns = ['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "#        'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "#        'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "#        'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "#        'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "#        'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "#        'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "#        'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "#        'symmetry_worst', 'fractal_dimension_worst'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9bf08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e7ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "X_scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fcf03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the scaler\n",
    "filename = 'scaler_allfeatures.sav'\n",
    "joblib.dump(X_scaler, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c858e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the training and testing data using the X_scaler model\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955d86ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124db6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1b905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "encoded_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a377d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1901e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with one model - Here, Random Classifier \n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train_scaled, encoded_y_train)\n",
    "rf.score(X_test_scaled, encoded_y_test)\n",
    "\n",
    "filename = 'rf.sav'\n",
    "joblib.dump(rf, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a51a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X_test_scaled, encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b7f5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check the importance of the features and remove the least important ones ( result was very similar so I did not do it)\n",
    "# sorted(zip(rf.feature_importances_, features), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d77d009",
   "metadata": {},
   "source": [
    "## Group 2:  Select features with selectBest function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff73124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SelectKBest (We will have to change the dataframes that feed into X and y):\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "X = features  #independent columns\n",
    "y = target    #target column i.e price range\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest()\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "#concat two dataframes for better visualization\n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(7,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153d5aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_sk = breast_cancer_df[['concave points_worst', 'perimeter_worst', 'concave points_mean',\n",
    "       'radius_worst', 'perimeter_mean', 'area_worst', 'radius_mean'\n",
    "       ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f880e510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data with features selected according to selectBest function\n",
    "X_train_sk, X_test_sk, y_train, y_test = train_test_split(features_sk, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cccae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data with features selected according to selectBest function\n",
    "X_scaler_sk = StandardScaler().fit(X_train_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2d81d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the scaler_sk\n",
    "filename = 'scaler_selectBestFeatures.sav'\n",
    "joblib.dump(X_scaler_sk, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb72107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the training and testing data using the X_scaler model\n",
    "X_train_scaled_sk = X_scaler_sk.transform(X_train_sk)\n",
    "X_test_scaled_sk = X_scaler_sk.transform(X_test_sk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67feac9e",
   "metadata": {},
   "source": [
    "## Group 3: Select features based on their correlation with each other and with the dignosis as determined in the correlation graph in tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65defb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cs = breast_cancer_df[['perimeter_worst',\n",
    "'concave points_worst',\n",
    "'symmetry_worst',\n",
    "'smoothness_worst',\n",
    "'compactness_worst',\n",
    "'texture_worst',\n",
    "'fractal_dimension_worst'\n",
    "       ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cba48e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data with features selected according to the correlation graph made in tableau\n",
    "X_train_cs, X_test_cs, y_train, y_test = train_test_split(features_cs, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57564282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data with features selected according to selectBest function\n",
    "X_scaler_cs = StandardScaler().fit(X_train_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dd0db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the scaler_sk\n",
    "filename = 'scaler_correlationFeatures.sav'\n",
    "joblib.dump(X_scaler_cs, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69092774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the training and testing data using the X_scaler model\n",
    "X_train_scaled_cs = X_scaler_sk.transform(X_train_cs)\n",
    "X_test_scaled_cs = X_scaler_sk.transform(X_test_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d72c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this code to load the scaler with all features \n",
    "# X_scaler = joblib.load(\"scaler_allfeatures.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147221cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this code to load the scaler with some features removed \n",
    "# X_scaler_r = joblib.load(\"scaler_features_removed.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa755051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train test data set for input with all features, selectBest features and correlation based features as csv file\n",
    "from numpy import asarray\n",
    "from numpy import savetxt\n",
    "\n",
    "savetxt('X_train_scaled.csv', X_train_scaled, delimiter=',')\n",
    "savetxt('X_test_scaled.csv', X_test_scaled , delimiter=',')\n",
    "savetxt('y_train_categorical.csv', y_train_categorical , delimiter=',')\n",
    "savetxt('y_test_categorical.csv', y_test_categorical , delimiter=',')\n",
    "savetxt('encoded_y_train.csv', encoded_y_train , delimiter=',')\n",
    "savetxt('encoded_y_test.csv', encoded_y_test , delimiter=',')\n",
    "savetxt('X_train_scaled_sk.csv', X_train_scaled_sk, delimiter=',')\n",
    "savetxt('X_test_scaled_sk.csv', X_test_scaled_sk , delimiter=',')\n",
    "savetxt('X_train_scaled_cs.csv', X_train_scaled_cs, delimiter=',')\n",
    "savetxt('X_test_scaled_cs.csv', X_test_scaled_cs , delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e35770",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
